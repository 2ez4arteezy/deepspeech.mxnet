[common]
# method can be one of the followings - train,predict,load
mode = train
#ex: gpu0,gpu1,gpu2,gpu3
context = gpu0
# checkpoint prefix
prefix = test_fc
model_file = test_fc-0001
batch_size = 2
log_filename = test.log
save_checkpoint_every_n_epoch = 1

[data]
train_json = ./Libri_sample.json
test_json = ./Libri_sample.json
val_json = ./Libri_sample.json

language = en
width = 161
height = 1
channel = 1
stride = 1

[arch]
channel_num = 32
conv_layer1_filter_dim = [11, 41]
conv_layer1_stride = [2, 2]
conv_layer2_filter_dim = [11, 21]
conv_layer2_stride = [1, 2]

num_rnn_layer = 3
num_hidden_rnn_list = [1760, 1760, 1760]
num_hidden_proj = 0

num_rear_fc_layers = 0
num_hidden_rear_fc_list = []
act_type_rear_fc_list = []

#network: lstm, bilstm, gru, bigru
rnn_type = bigru
#vanilla_lstm or fc_lstm (no effect when network_type is gru, bigru)
lstm_type = fc_lstm
batchnorm_yn = True

[train]
num_epoch = 5
# only normal, Another methods will be supported in the future.
method = normal

learning_rate = 0.0005
#decay_factor = 2
#decay_lower_bound = 1e-6
optimizer = adam
momentum = 0.9
# set to 0 to disable gradient clipping
clip_gradient = 0

initializer = Xavier
init_scale = 2.34
factor_type = in
weight_decay = 0.00001
# show progress every how many batches
show_every = 1
save_optimizer_states = True

[load]
load_optimizer_states = False
